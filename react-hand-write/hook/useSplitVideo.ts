/*
 * @Date: 2025-10-10 22:40:52
 * @Description:
 */
import { useCallback, useRef, useState, useEffect } from "react";
import { MD5WorkerPool } from "../worker/workpool";

export interface ChunkInfo {
  index: number;
  blob: Blob;
  size: number;
  md5?: string;
  retries: number;
  uploadProgress?: number;
}

export interface UploadProgress {
  totalBytes: number; // æ€»å­—èŠ‚æ•°
  uploadedBytes: number; // å·²ä¸Šä¼ å­—èŠ‚æ•°
  percentage: number; // ä¸Šä¼ ç™¾åˆ†æ¯”
  uploadSpeed: number; // ä¸Šä¼ é€Ÿåº¦ï¼ˆMB/sï¼‰
  remainingTime: number; // å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰
  uploadedChunks: number; // å·²ä¸Šä¼ åˆ†ç‰‡æ•°
  totalChunks: number; // æ€»åˆ†ç‰‡æ•°
  currentPhase: "preparing" | "calculating-md5" | "uploading" | "merging";
}

export interface UploadResult {
  success: boolean;
  fileId: string;
  filename: string;
  filepath: string;
  size: number;
  md5: string;
}
type UploadStatus =
  | "cancelled"
  | "idle"
  | "preparing"
  | "checking"
  | "uploading"
  | "merging"
  | "completed"
  | "error"
  | "calculating-md5"
  | "paused";

export interface UploadConfig {
  chunkSize?: number; // åˆ†ç‰‡å¤§å°ï¼Œé»˜è®¤10MB
  concurrentLimit?: number; // å¹¶å‘æ•°ï¼Œé»˜è®¤3
  maxRetries?: number; // æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3
  serverUrl?: string; // æœåŠ¡å™¨åœ°å€
  onProgress?: (progress: UploadProgress) => void;
  onChunkProgress?: (chunkIndex: number, progress: number) => void;
  onComplete?: (result: UploadResult) => void;
  onError?: (error: Error) => void;
  onStatusChange?: (status: UploadStatus) => void;
  onMD5Progress?: (progress: number) => void; // MD5è®¡ç®—è¿›åº¦å›è°ƒ
  workerPoolSize?: number; // Worker Poolå¤§å°ï¼Œé»˜è®¤2
}
const useSplitVideo = (config: UploadConfig = {}) => {
  const {
    chunkSize = 10 * 1024 * 1024,
    concurrentLimit = 3,
    maxRetries = 3,
    serverUrl = "/api",
    workerPoolSize = 2, // é»˜è®¤2ä¸ªWorker
    onProgress,
    onMD5Progress,
    onChunkProgress,
    onComplete,
    onError,
    onStatusChange,
  } = config;

  console.log(serverUrl);
  

  // Worker Poolå¼•ç”¨
  const workerPoolRef = useRef<MD5WorkerPool | null>(null);
  const chunksRef = useRef<ChunkInfo[]>([]);
  const startTimeRef = useRef<number>(0);
  const abortControllersRef = useRef<Map<number, AbortController>>(new Map());
  const fileIdRef = useRef<string>("");
  const currentFileRef = useRef<File | null>(null);

  // çŠ¶æ€ç®¡ç†

  const [uploadedChunks, setUploadedChunks] = useState<Set<number>>(new Set());
  const [md5Progress, setMd5Progress] = useState<number>(0);
  const [isPaused, setIsPaused] = useState(false);
  const [error, setError] = useState<string>("");
  const [isUploading, setIsUploading] = useState(false);
  const [status, setStatus] = useState<UploadStatus>("idle");
  const [progress, setProgress] = useState<UploadProgress>({
    totalBytes: 0,
    uploadedBytes: 0,
    percentage: 0,
    uploadSpeed: 0,
    remainingTime: 0,
    uploadedChunks: 0,
    totalChunks: 0,
    currentPhase: "preparing",
  });

  // åˆå§‹åŒ–Worker Poolï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
  useEffect(() => {
    workerPoolRef.current = new MD5WorkerPool(workerPoolSize);
    console.log(`âœ… Worker Poolå·²åˆå§‹åŒ–ï¼Œå¤§å°: ${workerPoolSize}`);
    return () => {
      // ç»„ä»¶å¸è½½æ—¶é”€æ¯Worker Pool
      workerPoolRef.current?.destroy();
      console.log("ğŸ—‘ï¸ Worker Poolå·²é”€æ¯");
    };
  }, [workerPoolSize]);

  // è®¡ç®—å‰©ä½™æ—¶é—´
  const calculateRemainingTime = (prog: UploadProgress): number => {
    const speed = prog.uploadSpeed;
    if (speed === 0) return 0;
    return (prog.totalBytes - prog.uploadedBytes) / (speed * 1024 * 1024);
  };
  // è®¡ç®—ä¸Šä¼ é€Ÿåº¦
  const calculateUploadSpeed = (uploadedBytes: number): number => {
    const elapsed = (Date.now() - startTimeRef.current) / 1000;
    return elapsed > 0 ? uploadedBytes / elapsed / (1024 * 1024) : 0;
  };

  // ä½¿ç”¨Worker Poolè®¡ç®—æ–‡ä»¶MD5
  const calculateFileMD5 = useCallback(
    async (file: File): Promise<string> => {
      if (!workerPoolRef.current) {
        throw new Error("Worker Poolæœªåˆå§‹åŒ–");
      }
      console.log("ğŸ“Š Worker PoolçŠ¶æ€:", workerPoolRef.current.getStatus());
      // ä½¿ç”¨Worker Poolè®¡ç®—MD5
      return workerPoolRef.current.calculateMD5(file, (progress) => {
        setMd5Progress(progress);
        onMD5Progress?.(progress);
      });
    },
    [onMD5Progress]
  );

  // å°†æ–‡ä»¶åˆ†ç‰‡
  const chunkFile = useCallback(
    (file: File): ChunkInfo[] => {
      const chunks: ChunkInfo[] = [];
      const totalChunks = Math.ceil(file.size / chunkSize);
      for (let i = 0; i < totalChunks; i++) {
        const start = i * chunkSize;
        const end = Math.min(start + chunkSize, file.size);
        chunks.push({
          index: i,
          blob: file.slice(start, end),
          size: end - start,
          retries: 0,
          uploadProgress: 0,
        });
      }
      return chunks;
    },
    [chunkSize]
  );

  // ä¸Šä¼ å•ä¸ªåˆ†ç‰‡ï¼ˆå¸¦è¿›åº¦ï¼‰
  const uploadChunk = useCallback(
    async (chunk: ChunkInfo, fileId: string): Promise<void> => {
      const formData = new FormData();
      formData.append("file", chunk.blob);
      formData.append("fileId", fileId);
      formData.append("chunkIndex", chunk.index.toString());

      const abortController = new AbortController();
      abortControllersRef.current.set(chunk.index, abortController);

      for (let i = 0; i <= maxRetries; i++) {
        try {
          if (isPaused) {
            throw new Error("ä¸Šä¼ å·²æš‚åœ");
          }

          await new Promise<void>((resolve, reject) => {
            const xhr = new XMLHttpRequest();

            xhr.upload.onprogress = (event) => {
              if (event.lengthComputable) {
                const chunkProgress = (event.loaded / event.total) * 100;
                chunk.uploadProgress = chunkProgress;
                onChunkProgress?.(chunk.index, chunkProgress);
              }
            };

            xhr.onload = () => {
              if (xhr.status >= 200 && xhr.status < 300) {
                try {
                  const data = JSON.parse(xhr.responseText);
                  if (data.success) {
                    resolve();
                  } else {
                    reject(new Error(data.message || "ä¸Šä¼ å¤±è´¥"));
                  }
                } catch (err) {
                  reject(new Error("è§£æå“åº”å¤±è´¥"));
                }
              } else {
                reject(new Error(`æœåŠ¡å™¨é”™è¯¯: ${xhr.status}`));
              }
            };

            xhr.onerror = () => reject(new Error("ç½‘ç»œé”™è¯¯"));
            xhr.onabort = () => reject(new Error("ä¸Šä¼ å·²ä¸­æ–­"));

            abortController.signal.addEventListener("abort", () => {
              xhr.abort();
            });

            // å°† fileId å’Œ chunkIndex ä½œä¸º query å‚æ•°ä¼ é€’ï¼ˆå› ä¸º multer åœ¨å¤„ç†æ–‡ä»¶æ—¶ req.body è¿˜æœªè§£æï¼‰
            xhr.open("POST", `${serverUrl}/upload/chunk?fileId=${encodeURIComponent(fileId)}&chunkIndex=${chunk.index}`);
            xhr.send(formData);
          });

          setUploadedChunks((prev) => new Set([...prev, chunk.index]));
          setProgress((prev) => {
            const newProgress = {
              ...prev,
              uploadedBytes: prev.uploadedBytes + chunk.size,
              uploadedChunks: prev.uploadedChunks + 1,
              currentPhase: "uploading" as const,
            };
            newProgress.percentage =
              (newProgress.uploadedBytes / newProgress.totalBytes) * 100;
            newProgress.uploadSpeed = calculateUploadSpeed(
              newProgress.uploadedBytes
            );
            newProgress.remainingTime = calculateRemainingTime(newProgress);

            onProgress?.(newProgress);
            return newProgress;
          });

          abortControllersRef.current.delete(chunk.index);
          return;
        } catch (err) {
          if (err instanceof Error && err.message === "ä¸Šä¼ å·²ä¸­æ–­") {
            throw err;
          }

          if (i === maxRetries) {
            throw err;
          }
          await new Promise((resolve) =>
            setTimeout(resolve, Math.pow(2, i) * 1000)
          );
        }
      }
    },
    [serverUrl, maxRetries, isPaused, onProgress, onChunkProgress]
  );
  // ç§’ä¼ æ£€æŸ¥
  const checkSecondaryUpload = useCallback(
    async (fileMD5: string, filename: string): Promise<boolean> => {
      try {
        const response = await fetch(`${serverUrl}/upload/check`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ fileMD5, filename }),
        });
        const data = await response.json();
        if (data.exists) {
          onComplete?.({
            success: true,
            fileId: fileMD5,
            filename,
            filepath: data.path,
            size: 0,
            md5: fileMD5,
          });
          return true;
        }
        return false;
      } catch (err) {
        console.error("ç§’ä¼ æ£€æŸ¥å¤±è´¥:", err);
        return false;
      }
    },
    [serverUrl, onComplete]
  );

  // æŸ¥è¯¢å·²ä¸Šä¼ çš„åˆ†ç‰‡
  const checkUploadedChunks = useCallback(
    async (fileId: string): Promise<number[]> => {
      try {
        const response = await fetch(`${serverUrl}/upload/chunks/${fileId}`);
        const data = await response.json();
        return data.chunks || [];
      } catch (err) {
        console.error("æŸ¥è¯¢å·²ä¸Šä¼ åˆ†ç‰‡å¤±è´¥:", err);
        return [];
      }
    },
    [serverUrl]
  );

  // åˆå¹¶åˆ†ç‰‡
  const mergeChunks = useCallback(
    async (
      fileId: string,
      totalChunks: number,
      filename: string
    ): Promise<UploadResult> => {
      setStatus("merging");
      setProgress((prev) => ({ ...prev, currentPhase: "merging" }));

      try {
        const response = await fetch(`${serverUrl}/upload/merge`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ fileId, totalChunks, filename }),
        });

        const data = await response.json();
        if (data.success) {
          const result: UploadResult = {
            success: true,
            fileId,
            filename,
            filepath: data.path,
            size: data.size,
            md5: data.md5,
          };
          onComplete?.(result);
          setStatus("completed");
          return result;
        } else {
          throw new Error(data.message || "åˆå¹¶å¤±è´¥");
        }
      } catch (err) {
        const errorMsg = err instanceof Error ? err.message : "åˆå¹¶åˆ†ç‰‡å¤±è´¥";
        setError(errorMsg);
        setStatus("error");
        onError?.(new Error(errorMsg));
        throw err;
      }
    },
    [serverUrl, onComplete, onError]
  );

  // å¹¶å‘ä¸Šä¼ æ§åˆ¶
  const uploadChunksWithLimit = useCallback(
    async (chunks: ChunkInfo[], fileId: string): Promise<void> => {
      const queue = chunks.filter((c) => !uploadedChunks.has(c.index));
      const uploading = new Map<number, Promise<void>>();

      while (queue.length > 0 || uploading.size > 0) {
        // æš‚åœä¸Šä¼ 
        if (isPaused) {
          await new Promise((resolve) => setTimeout(resolve, 500));
          continue;
        }

        // å¯åŠ¨æ–°çš„ä¸Šä¼ ä»»åŠ¡
        while (uploading.size < concurrentLimit && queue.length > 0) {
          const chunk = queue.shift()!;
          const uploadPromise = uploadChunk(chunk, fileId)
            .catch((err) => {
              console.error(`åˆ†ç‰‡ ${chunk.index} ä¸Šä¼ å¤±è´¥:`, err);
              // é‡æ–°åŠ å…¥é˜Ÿåˆ—ï¼ˆå¦‚æœè¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼‰
              if (chunk.retries < maxRetries) {
                chunk.retries++;
                queue.push(chunk);
              } else {
                throw err;
              }
            })
            .finally(() => {
              uploading.delete(chunk.index);
            });
          uploading.set(chunk.index, uploadPromise);
        }

        // ç­‰å¾…è‡³å°‘ä¸€ä¸ªä¸Šä¼ å®Œæˆ
        if (uploading.size > 0) {
          await Promise.race(Array.from(uploading.values()));
        }
      }
    },
    [uploadedChunks, isPaused, concurrentLimit, uploadChunk, maxRetries]
  );
  // ä¸Šä¼ æ–‡ä»¶
  const uploadFile = useCallback(
    async (file: File): Promise<UploadResult | null> => {
      try {
        setStatus("preparing");
        setIsUploading(true);
        setError("");
        setIsPaused(false);
        startTimeRef.current = Date.now();
        currentFileRef.current = file;

        setProgress((prev) => ({
          ...prev,
          totalBytes: file.size,
          uploadedBytes: 0,
          percentage: 0,
          currentPhase: "preparing",
        }));

        fileIdRef.current = `${Date.now()}_${Math.random()
          .toString(36)
          .substr(2, 9)}`;

        // è®¡ç®—MD5ï¼ˆä½¿ç”¨Worker Poolï¼‰
        setStatus("calculating-md5");
        console.log("ğŸ” å¼€å§‹è®¡ç®—MD5ï¼Œä½¿ç”¨Worker Pool...");
        const fileMD5 = await calculateFileMD5(file);
        console.log(fileMD5);
        
        console.log("âœ… MD5è®¡ç®—å®Œæˆ:", fileMD5);
      

        // ç§’ä¼ æ£€æŸ¥ï¼ˆç•¥è¿‡ï¼Œå‡è®¾æ–‡ä»¶ä¸å­˜åœ¨ï¼‰
        // ç§’ä¼ æ£€æŸ¥
        setStatus("checking");
        const isSecondaryUpload = await checkSecondaryUpload(
          fileMD5,
          file.name
        );
        if (isSecondaryUpload) {
          setStatus("completed");
          setIsUploading(false);
          return null;
        }
        // åˆ†ç‰‡å¤„ç†
        setStatus("preparing");
        const chunks = chunkFile(file);
        chunksRef.current = chunks;
        setProgress((prev) => ({
          ...prev,
          totalChunks: chunks.length,
          uploadedChunks: 0,
          currentPhase: "uploading",
        }));

        // æŸ¥è¯¢å·²ä¸Šä¼ çš„åˆ†ç‰‡ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
        const uploaded = await checkUploadedChunks(fileIdRef.current);
        setUploadedChunks(new Set(uploaded));
        // å¹¶å‘ä¸Šä¼ åˆ†ç‰‡
        setStatus("uploading");
        await uploadChunksWithLimit(chunks, fileIdRef.current);
        // åˆå¹¶åˆ†ç‰‡
        const result = await mergeChunks(
          fileIdRef.current,
          chunks.length,
          file.name
        );
        setIsUploading(false);
        return result;
      } catch (err) {
        if (err instanceof Error && err.message === "MD5è®¡ç®—å·²ä¸­æ–­") {
          setStatus("cancelled");
          setError("ä¸Šä¼ å·²å–æ¶ˆ");
        } else {
          const errorMsg = err instanceof Error ? err.message : "ä¸Šä¼ å¤±è´¥";
          setError(errorMsg);
          setStatus("error");
          onError?.(new Error(errorMsg));
        }
        setIsUploading(false);
        return null;
      }
    },
    [calculateFileMD5, chunkFile, onError]
  );

  // æš‚åœä¸Šä¼ 
  const pauseUpload = useCallback(() => {
    setIsPaused(true);
    setStatus("paused");
    onStatusChange?.("paused");
  }, [onStatusChange]);

  // æ¢å¤ä¸Šä¼ 
  const resumeUpload = useCallback(() => {
    setIsPaused(false);
    setStatus("uploading");
    onStatusChange?.("uploading");
  }, [onStatusChange]);

  // å–æ¶ˆä¸Šä¼ 
  const cancelUpload = useCallback(() => {
    // ä¸­æ­¢æ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„ä¸Šä¼ 
    abortControllersRef.current.forEach((controller) => {
      controller.abort();
    });
    abortControllersRef.current.clear();

    // æ¸…ç©º Worker Pool
    workerPoolRef.current?.clear();

    setStatus("cancelled");
    setIsUploading(false);
    setError("ä¸Šä¼ å·²å–æ¶ˆ");
    onStatusChange?.("cancelled");
  }, [onStatusChange]);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      // å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„ä¸Šä¼ 
      abortControllersRef.current.forEach((controller) => {
        controller.abort();
      });
      abortControllersRef.current.clear();
    };
  }, []);

  return {
    uploadFile,
    chunkFile,
    pauseUpload,
    resumeUpload,
    cancelUpload,
    // çŠ¶æ€
    status,
    progress,
    md5Progress,
    isPaused,
    isUploading,
    error,
  };
};

export default useSplitVideo;
